{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PassengerId</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             Survived  Pclass  \\\n",
       "PassengerId                     \n",
       "1                   0       3   \n",
       "2                   1       1   \n",
       "3                   1       3   \n",
       "4                   1       1   \n",
       "5                   0       3   \n",
       "\n",
       "                                                          Name     Sex   Age  \\\n",
       "PassengerId                                                                    \n",
       "1                                      Braund, Mr. Owen Harris    male  22.0   \n",
       "2            Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0   \n",
       "3                                       Heikkinen, Miss. Laina  female  26.0   \n",
       "4                 Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0   \n",
       "5                                     Allen, Mr. William Henry    male  35.0   \n",
       "\n",
       "             SibSp  Parch            Ticket     Fare Cabin Embarked  \n",
       "PassengerId                                                          \n",
       "1                1      0         A/5 21171   7.2500   NaN        S  \n",
       "2                1      0          PC 17599  71.2833   C85        C  \n",
       "3                0      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "4                1      0            113803  53.1000  C123        S  \n",
       "5                0      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv('../data/titanic_train.csv',\n",
    "                  index_col='PassengerId')\n",
    "\n",
    "data['Age'].fillna(data['Age'].median(), inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "X = data[[\"Fare\", \"Age\"]].head(200).to_numpy()\n",
    "#X = data[[\"Fare\", \"Age\"]].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "Y = data[\"Survived\"].head(200).to_numpy()\n",
    "#Y = data[\"Survived\"].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "class DecisionTreeBinaryClassifier():\n",
    "    '''\n",
    "    Реализация алгоритма бинарного дерева для классификации\n",
    "    на основе максимизации неопределенности Джини\n",
    "    '''\n",
    "    def __init__(self, max_depth = None, n_classes = 2, verboose = True):\n",
    "        self.max_depth = max_depth # максимальная глубина дерева\n",
    "        self.n_classes = n_classes # количество классов (по умолчанию бинарная классификация)\n",
    "        self.classes = range(0, self.n_classes) # список уникальных классов\n",
    "        self.verboose = verboose\n",
    "        self.node = None\n",
    "\n",
    "    class Node():\n",
    "        ''' Класс представляющий узел бинарного дерева '''\n",
    "        def __init__(self, pred_class,\n",
    "                     gini,\n",
    "                     feature_id,\n",
    "                     feature_value,\n",
    "                     depth,\n",
    "                     right_node = None,\n",
    "                     left_node = None):\n",
    "            self.pred_class = pred_class\n",
    "            self.gini = gini\n",
    "            self.feature_id = feature_id\n",
    "            self.feature_value = feature_value\n",
    "            self.depth = depth\n",
    "            self.right_node = right_node\n",
    "            self.left_node = left_node\n",
    "\n",
    "        def __str__(self):\n",
    "            return \"\"\"\n",
    "                Decision Tree Node\n",
    "                ------------------\n",
    "                pred_class: {pred_class}\n",
    "                gini: {gini}\n",
    "                feature_id: {feature_id}\n",
    "                feature_value: {feature_value}\n",
    "                depth: {depth}\n",
    "                \n",
    "                right_node: {right_node}\n",
    "                ========================\n",
    "                left_node: {left_node}\n",
    "                \n",
    "                \"\"\".format(pred_class=str(self.pred_class),\n",
    "                           gini=str(self.gini),\n",
    "                           feature_id=str(self.feature_id),\n",
    "                           feature_value=str(self.feature_value),\n",
    "                           depth=str(self.depth),\n",
    "                           right_node=str(self.right_node),\n",
    "                           left_node=str(self.left_node))\n",
    "\n",
    "    def log(self, s):\n",
    "        if self.verboose:\n",
    "            print(s)\n",
    "\n",
    "\n",
    "    def _gini(self, node_y):\n",
    "        '''Расчитывает неопределенность Джини по одному узлу\n",
    "        :param node_y: метки классов в узле\n",
    "        '''\n",
    "        return 1.0 - sum([(float(np.sum(node_y == cl))/node_y.size)**2 for cl in self.classes])\n",
    "\n",
    "\n",
    "    def _split(self, data, id):\n",
    "        ''' Разбивает датасет по определенному параметру\n",
    "        :param data: numpy array\n",
    "        :param id: индекс по которому идет разбиение\n",
    "        :return: left_data, right_data\n",
    "        '''\n",
    "        if id == 0:\n",
    "            return data[:id+1], data[id+1:]\n",
    "        else:\n",
    "            return data[:id], data[id:]\n",
    "\n",
    "\n",
    "    def _search_split_id(self, Y):\n",
    "        '''Возвращает список индексов в которых целевая переменная изменяется'''\n",
    "        split_ids = []\n",
    "        for i in range(0, len(Y) - 1):\n",
    "            if Y[i] - Y[i + 1] != 0:\n",
    "                split_ids.append(i)\n",
    "        return split_ids\n",
    "\n",
    "\n",
    "    def _best_split(self, X, Y, depth):\n",
    "        ''' Ищем наилучшее разбиение '''\n",
    "        n_features = X.shape[1]\n",
    "        max_gini = float()\n",
    "        best_feature_id = None\n",
    "        best_feature_value = None\n",
    "        for feature in range(0,  n_features):\n",
    "            learning_data, target_data = zip(*sorted(zip(X[:, feature], Y)))\n",
    "            split_ids = self._search_split_id(Y)\n",
    "            for id in split_ids:\n",
    "                left_Y, right_Y = self._split(Y, id)\n",
    "                gini = (\n",
    "                    (float(len(left_Y))/ len(target_data)) * self._gini(left_Y)\n",
    "                    +\n",
    "                    (float(len(right_Y)) / len(target_data)) * self._gini(right_Y)\n",
    "                )\n",
    "                fv = (learning_data[id]+learning_data[id+1])/2\n",
    "                if gini > max_gini:\n",
    "                    max_gini = gini\n",
    "                    best_feature_id = feature\n",
    "                    best_feature_value = fv\n",
    "\n",
    "                self.log(\"depth: {depth}, feature_id: {feature}, feature_value: {feature_value}, gini: {gini}, max_gini: {max_gini}\" \\\n",
    "                         .format(depth=str(depth),\n",
    "                                 feature=str(feature),\n",
    "                                 feature_value=str(fv),\n",
    "                                 gini=str(gini),\n",
    "                                 max_gini=str(max_gini)\n",
    "                         ))\n",
    "\n",
    "        return self.Node(pred_class = round(np.mean(Y),0),\n",
    "                         gini = max_gini,\n",
    "                         feature_id = best_feature_id,\n",
    "                         feature_value = best_feature_value,\n",
    "                         depth = depth,\n",
    "                         right_node = None,\n",
    "                         left_node = None)\n",
    "\n",
    "\n",
    "    def _fit(self, X, Y, depth):        \n",
    "        if depth <= self.max_depth:\n",
    "            node = self._best_split(X, Y, depth)\n",
    "            id_left = np.ndarray.flatten(X[:, node.feature_id] < node.feature_value)\n",
    "            if id_left is not None:\n",
    "                if id_left.size == Y.size:\n",
    "                    X_left, Y_left = X[id_left], Y[id_left]\n",
    "                    X_right, Y_right = X[~id_left], Y[~id_left]\n",
    "                    node.left_node = self._fit(X_left, Y_left, depth+1)\n",
    "                    node.right_node = self._fit(X_right, Y_right, depth+1)\n",
    "                    return node\n",
    "\n",
    "    def fit(self, X, Y):\n",
    "        self.node = self._fit(X, Y, 1)\n",
    "\n",
    "\n",
    "    def _predict(self, node, row):\n",
    "        '''Рекурсивно делает предсказание для одной строки данных'''\n",
    "        if row[node.feature_id] < node.feature_value:\n",
    "            if node.left_node is not None:\n",
    "                return self._predict(node.left_node, row)\n",
    "            else:\n",
    "                return node.pred_class\n",
    "        else:\n",
    "            if node.right_node is not None:\n",
    "                return self._predict(node.right_node, row)\n",
    "            else:\n",
    "                return node.pred_class\n",
    "\n",
    "\n",
    "    def predict(self, X):\n",
    "        return [self._predict(self.node, row) for row in X]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "                Decision Tree Node\n",
      "                ------------------\n",
      "                pred_class: 0.0\n",
      "                gini: 0.451945854484\n",
      "                feature_id: 0\n",
      "                feature_value: 255.2604\n",
      "                depth: 1\n",
      "                \n",
      "                right_node: None\n",
      "                ========================\n",
      "                left_node: \n",
      "                Decision Tree Node\n",
      "                ------------------\n",
      "                pred_class: 0.0\n",
      "                gini: 0.450971250971\n",
      "                feature_id: 0\n",
      "                feature_value: 146.5208\n",
      "                depth: 2\n",
      "                \n",
      "                right_node: \n",
      "                Decision Tree Node\n",
      "                ------------------\n",
      "                pred_class: 1.0\n",
      "                gini: 0.333333333333\n",
      "                feature_id: 0\n",
      "                feature_value: 146.5208\n",
      "                depth: 3\n",
      "                \n",
      "                right_node: None\n",
      "                ========================\n",
      "                left_node: None\n",
      "                \n",
      "                \n",
      "                ========================\n",
      "                left_node: \n",
      "                Decision Tree Node\n",
      "                ------------------\n",
      "                pred_class: 0.0\n",
      "                gini: 0.44780982906\n",
      "                feature_id: 0\n",
      "                feature_value: 81.08539999999999\n",
      "                depth: 3\n",
      "                \n",
      "                right_node: None\n",
      "                ========================\n",
      "                left_node: None\n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n",
      "                \n"
     ]
    }
   ],
   "source": [
    "tree = DecisionTreeBinaryClassifier(max_depth=3, verboose = False)\n",
    "tree.fit(X, Y)\n",
    "print(tree.node)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.66"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(Y, tree.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_gini = DecisionTreeClassifier(criterion='gini', max_depth=3, random_state=17)\n",
    "tree_gini.fit(X, Y)\n",
    "accuracy_score(Y, tree_gini.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.685"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_ent = DecisionTreeClassifier(criterion='entropy', max_depth=3, random_state=17)\n",
    "tree_ent.fit(X, Y)\n",
    "accuracy_score(Y, tree_ent.predict(X))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier, export_graphviz\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import roc_auc_score, accuracy_score, confusion_matrix\n",
    "%matplotlib inline\n",
    "from matplotlib import pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.read_csv(\"../data/titanic_train.csv\") \n",
    "test_df = pd.read_csv(\"../data/titanic_test.csv\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "y_train = train_df['Survived']\n",
    "#y_test = test_df['Survived']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "test_df['Age'].fillna(train_df['Age'].median(), inplace=True)\n",
    "train_df['Embarked'].fillna('S', inplace=True)\n",
    "test_df['Fare'].fillna(train_df['Fare'].median(), inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df = pd.concat([train_df, pd.get_dummies(train_df['Pclass'], \n",
    "                                               prefix=\"PClass\"),\n",
    "                      pd.get_dummies(train_df['Sex'], prefix=\"Sex\"),\n",
    "                      pd.get_dummies(train_df['SibSp'], prefix=\"SibSp\"),\n",
    "                      pd.get_dummies(train_df['Parch'], prefix=\"Parch\"),\n",
    "                     pd.get_dummies(train_df['Embarked'], prefix=\"Embarked\")],\n",
    "                     axis=1)\n",
    "test_df = pd.concat([test_df, pd.get_dummies(test_df['Pclass'], \n",
    "                                             prefix=\"PClass\"),\n",
    "                      pd.get_dummies(test_df['Sex'], prefix=\"Sex\"),\n",
    "                      pd.get_dummies(test_df['SibSp'], prefix=\"SibSp\"),\n",
    "                      pd.get_dummies(test_df['Parch'], prefix=\"Parch\"),\n",
    "                    pd.get_dummies(test_df['Embarked'], prefix=\"Embarked\")],\n",
    "                     axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_df.drop(['Survived', 'Pclass', 'Name', 'Sex', 'SibSp', \n",
    "               'Parch', 'Ticket', 'Cabin', 'Embarked', 'PassengerId'], \n",
    "              axis=1, inplace=True)\n",
    "test_df.drop(['Pclass', 'Name', 'Sex', 'SibSp', 'Parch', 'Ticket', 'Cabin', 'Embarked', 'PassengerId'], \n",
    "             axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 174,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Age</th>\n",
       "      <th>Fare</th>\n",
       "      <th>PClass_1</th>\n",
       "      <th>PClass_2</th>\n",
       "      <th>PClass_3</th>\n",
       "      <th>Sex_female</th>\n",
       "      <th>Sex_male</th>\n",
       "      <th>SibSp_0</th>\n",
       "      <th>SibSp_1</th>\n",
       "      <th>SibSp_2</th>\n",
       "      <th>...</th>\n",
       "      <th>Parch_0</th>\n",
       "      <th>Parch_1</th>\n",
       "      <th>Parch_2</th>\n",
       "      <th>Parch_3</th>\n",
       "      <th>Parch_4</th>\n",
       "      <th>Parch_5</th>\n",
       "      <th>Parch_6</th>\n",
       "      <th>Embarked_C</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>22.0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>38.0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>26.0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>35.0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>35.0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    Age     Fare  PClass_1  PClass_2  PClass_3  Sex_female  Sex_male  SibSp_0  \\\n",
       "0  22.0   7.2500         0         0         1           0         1        0   \n",
       "1  38.0  71.2833         1         0         0           1         0        0   \n",
       "2  26.0   7.9250         0         0         1           1         0        1   \n",
       "3  35.0  53.1000         1         0         0           1         0        0   \n",
       "4  35.0   8.0500         0         0         1           0         1        1   \n",
       "\n",
       "   SibSp_1  SibSp_2  ...  Parch_0  Parch_1  Parch_2  Parch_3  Parch_4  \\\n",
       "0        1        0  ...        1        0        0        0        0   \n",
       "1        1        0  ...        1        0        0        0        0   \n",
       "2        0        0  ...        1        0        0        0        0   \n",
       "3        1        0  ...        1        0        0        0        0   \n",
       "4        0        0  ...        1        0        0        0        0   \n",
       "\n",
       "   Parch_5  Parch_6  Embarked_C  Embarked_Q  Embarked_S  \n",
       "0        0        0           0           0           1  \n",
       "1        0        0           1           0           0  \n",
       "2        0        0           0           0           1  \n",
       "3        0        0           0           0           1  \n",
       "4        0        0           0           0           1  \n",
       "\n",
       "[5 rows x 24 columns]"
      ]
     },
     "execution_count": 174,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((891, 24), (418, 25))"
      ]
     },
     "execution_count": 294,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df.shape, test_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Parch_9'}"
      ]
     },
     "execution_count": 295,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(test_df.columns) - set(train_df.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_df.drop(['Parch_9'], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите на имеющейся выборке дерево решений (DecisionTreeClassifier) максимальной глубины 2. Используйте параметр random_state=17 для воспроизводимости результатов."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "tree_ent = DecisionTreeClassifier(criterion='entropy', max_depth=2, random_state=17)\n",
    "tree_gini = DecisionTreeClassifier(criterion='gini', max_depth=2, random_state=17)\n",
    "my_tree = DecisionTreeBinaryClassifier(max_depth=2, verboose = False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 298,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=17,\n",
       "            splitter='best')"
      ]
     },
     "execution_count": 298,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_ent.fit(train_df, y_train)\n",
    "tree_gini.fit(train_df, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Сделайте с помощью полученной модели прогноз для тестовой выборки"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 299,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pred_ent = tree_ent.predict(train_df)\n",
    "pred_gigni = tree_gini.predict(train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "entropy: 0.7867564534231201\n",
      "gini: 0.7957351290684624\n"
     ]
    }
   ],
   "source": [
    "print(\"entropy: \" + str(accuracy_score(pred_ent, y_train)))\n",
    "print(\"gini: \" + str(accuracy_score(pred_gigni, y_train)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Отобразите дерево с помощью export_graphviz и dot."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 301,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# используем .dot формат для визуализации дерева\n",
    "from ipywidgets import Image\n",
    "from io import StringIO\n",
    "import pydotplus\n",
    "from sklearn.tree import export_graphviz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 302,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unicode argument expected, got 'str'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-302-b2d3335ed0e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mdot_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mStringIO\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m export_graphviz(tree_gini, feature_names=train_df.columns, \n\u001b[0;32m----> 3\u001b[0;31m                 out_file=dot_data, filled=True)\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mgraph\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpydotplus\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgraph_from_dot_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdot_data\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mImage\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvalue\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mgraph\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcreate_png\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/home/makilins/.local/lib/python2.7/site-packages/sklearn/tree/export.pyc\u001b[0m in \u001b[0;36mexport_graphviz\u001b[0;34m(decision_tree, out_file, max_depth, feature_names, class_names, label, filled, leaves_parallel, impurity, node_ids, proportion, rotate, rounded, special_characters, precision)\u001b[0m\n\u001b[1;32m    432\u001b[0m         \u001b[0mcolors\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0;34m'bounds'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mNone\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    433\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 434\u001b[0;31m         \u001b[0mout_file\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwrite\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'digraph Tree {\\n'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    435\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    436\u001b[0m         \u001b[0;31m# Specify node aesthetics\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unicode argument expected, got 'str'"
     ]
    }
   ],
   "source": [
    "dot_data = StringIO()\n",
    "export_graphviz(tree_gini, feature_names=train_df.columns, \n",
    "                out_file=dot_data, filled=True)\n",
    "graph = pydotplus.graph_from_dot_data(dot_data.getvalue())  \n",
    "Image(value=graph.create_png())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучите на имеющейся выборке дерево решений (DecisionTreeClassifier). Также укажите random_state=17. Максимальную глубину и минимальное число элементов в листе настройте на 5-кратной кросс-валидации с помощью GridSearchCV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 303,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_params = {'max_depth': list(range(1, 5)), \n",
    "               'min_samples_leaf': list(range(1, 5))}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 304,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV, cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "tree_grid = GridSearchCV(tree_gini, tree_params, cv=5, n_jobs=1, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 306,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 16 candidates, totalling 80 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done  80 out of  80 | elapsed:    0.6s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=5, error_score='raise-deprecating',\n",
       "       estimator=DecisionTreeClassifier(class_weight=None, criterion='gini', max_depth=2,\n",
       "            max_features=None, max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, presort=False, random_state=17,\n",
       "            splitter='best'),\n",
       "       fit_params=None, iid='warn', n_jobs=1,\n",
       "       param_grid={'max_depth': [1, 2, 3, 4], 'min_samples_leaf': [1, 2, 3, 4]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score='warn',\n",
       "       scoring=None, verbose=True)"
      ]
     },
     "execution_count": 306,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.fit(train_df, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8103254769921436"
      ]
     },
     "execution_count": 307,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.best_score_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'max_depth': 3, 'min_samples_leaf': 3}"
      ]
     },
     "execution_count": 308,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 309,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 1, 1, 0, 0, 1, 1, 0, 0,\n",
       "       1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 1,\n",
       "       1, 0, 0, 1, 1, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 1, 1,\n",
       "       1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0,\n",
       "       0, 1, 1, 1, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
       "       0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1,\n",
       "       0, 0, 1, 1, 0, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1, 1, 0, 0, 0, 0, 0, 1,\n",
       "       1, 0, 1, 1, 0, 0, 1, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1,\n",
       "       0, 1, 1, 1, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 1, 1, 0, 1, 0, 1, 0,\n",
       "       1, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1,\n",
       "       0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0,\n",
       "       0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 1,\n",
       "       0, 1, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0,\n",
       "       1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 1, 0, 1, 1, 0,\n",
       "       0, 0, 1, 0, 1, 0, 0, 1, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 1, 0, 0,\n",
       "       1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 0, 1, 0, 0, 0, 1, 0, 1, 0, 0, 0, 1,\n",
       "       0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 0])"
      ]
     },
     "execution_count": 309,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tree_grid.predict(test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
